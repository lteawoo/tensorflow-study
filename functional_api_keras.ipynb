{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a13dbea-2423-4c7d-a1fd-8703f37468ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 05:08:44.957420: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#Sequntial API 모델\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(3, input_dim=4, activation='softmax'))\n",
    "\n",
    "#직관적이고 편리하지만 단순히 층을 쌓는 것만으로는 구현할 수 없는 복잡한 신경망을 구현할 수 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21b3638f-3227-476c-97b6-ea43fc447d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functional API로 만든 모델\n",
    "# 각 층을 일종의 함수로 정의, 함수를 조합하기 위해 연산자를 제공\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb33858a-64d2-4ab9-a566-a8dd0acf0336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전결합 피드 포워드 신경망 (Fully-connected FFNN)\n",
    "# 가장 단순한 신경망\n",
    "# functional API 에서는 입력 데이터의 크기(shape)를 인자로 입력층을 정의해주어야 한다.\n",
    "\n",
    "# 10개의 입력을 받는 입력층\n",
    "inputs = Input(shape=(10,))\n",
    "hidden1 = Dense(64, activation='relu')(inputs)\n",
    "hidden2 = Dense(64, activation='relu')(inputs)\n",
    "output = Dense(1, activation='sigmoid')(hidden2)\n",
    "\n",
    "# 하나의 모델로 구성\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "# model로 구성하면 sequential api 와 마찬가지로 컴파일과 학습 등이 가능\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.fit(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f956b5ff-fe8a-43f2-9573-a69bd5954e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 3482.2139 - mse: 3482.2139\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 429.5128 - mse: 429.5128\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 53.8998 - mse: 53.8998\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.6824 - mse: 7.6824\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.9947 - mse: 1.9947\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2938 - mse: 1.2938\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2066 - mse: 1.2066\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1949 - mse: 1.1949\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1925 - mse: 1.1925\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1913 - mse: 1.1913\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1902 - mse: 1.1902\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1891 - mse: 1.1891\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1881 - mse: 1.1881\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1870 - mse: 1.1870\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1860 - mse: 1.1860\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1849 - mse: 1.1849\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1839 - mse: 1.1839\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1829 - mse: 1.1829\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1819 - mse: 1.1819\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1809 - mse: 1.1809\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1799 - mse: 1.1799\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1789 - mse: 1.1789\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1779 - mse: 1.1779\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1770 - mse: 1.1770\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1760 - mse: 1.1760\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1751 - mse: 1.1751\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1741 - mse: 1.1741\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1732 - mse: 1.1732\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1723 - mse: 1.1723\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1713 - mse: 1.1713\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1704 - mse: 1.1704\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1695 - mse: 1.1695\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1686 - mse: 1.1686\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1677 - mse: 1.1677\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1668 - mse: 1.1668\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1660 - mse: 1.1660\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1651 - mse: 1.1651\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1642 - mse: 1.1642\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1634 - mse: 1.1634\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1625 - mse: 1.1625\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1617 - mse: 1.1617\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1609 - mse: 1.1609\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1600 - mse: 1.1600\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1592 - mse: 1.1592\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1584 - mse: 1.1584\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1576 - mse: 1.1576\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1568 - mse: 1.1568\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1560 - mse: 1.1560\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1552 - mse: 1.1552\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1544 - mse: 1.1544\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1536 - mse: 1.1536\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1529 - mse: 1.1529\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1521 - mse: 1.1521\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1514 - mse: 1.1514\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1506 - mse: 1.1506\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1499 - mse: 1.1499\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1491 - mse: 1.1491\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1484 - mse: 1.1484\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1477 - mse: 1.1477\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1469 - mse: 1.1469\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1462 - mse: 1.1462\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1455 - mse: 1.1455\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1448 - mse: 1.1448\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1441 - mse: 1.1441\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1434 - mse: 1.1434\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1428 - mse: 1.1428\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1421 - mse: 1.1421\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1414 - mse: 1.1414\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1407 - mse: 1.1407\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1401 - mse: 1.1401\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1394 - mse: 1.1394\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1388 - mse: 1.1388\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1381 - mse: 1.1381\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1375 - mse: 1.1375\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1368 - mse: 1.1368\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1362 - mse: 1.1362\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1356 - mse: 1.1356\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1350 - mse: 1.1350\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1343 - mse: 1.1343\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1337 - mse: 1.1337\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1331 - mse: 1.1331\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1325 - mse: 1.1325\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1319 - mse: 1.1319\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1313 - mse: 1.1313\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1308 - mse: 1.1308\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1302 - mse: 1.1302\n",
      "Epoch 87/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1296 - mse: 1.1296\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1290 - mse: 1.1290\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1285 - mse: 1.1285\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1279 - mse: 1.1279\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1273 - mse: 1.1273\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1268 - mse: 1.1268\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1262 - mse: 1.1262\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1257 - mse: 1.1257\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1252 - mse: 1.1252\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1246 - mse: 1.1246\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1241 - mse: 1.1241\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1236 - mse: 1.1236\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1230 - mse: 1.1230\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1225 - mse: 1.1225\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1220 - mse: 1.1220\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1215 - mse: 1.1215\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1210 - mse: 1.1210\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1205 - mse: 1.1205\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1200 - mse: 1.1200\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1195 - mse: 1.1195\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1190 - mse: 1.1190\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1185 - mse: 1.1185\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1180 - mse: 1.1180\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1176 - mse: 1.1176\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1171 - mse: 1.1171\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1166 - mse: 1.1166\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1162 - mse: 1.1162\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1157 - mse: 1.1157\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1152 - mse: 1.1152\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1148 - mse: 1.1148\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1143 - mse: 1.1143\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1139 - mse: 1.1139\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1135 - mse: 1.1135\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1130 - mse: 1.1130\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1126 - mse: 1.1126\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1121 - mse: 1.1121\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1117 - mse: 1.1117\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1113 - mse: 1.1113\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1109 - mse: 1.1109\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1104 - mse: 1.1104\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1100 - mse: 1.1100\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1096 - mse: 1.1096\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1092 - mse: 1.1092\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1088 - mse: 1.1088\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1084 - mse: 1.1084\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1080 - mse: 1.1080\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1076 - mse: 1.1076\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1072 - mse: 1.1072\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1068 - mse: 1.1068\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1065 - mse: 1.1065\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1061 - mse: 1.1061\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1057 - mse: 1.1057\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1053 - mse: 1.1053\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1049 - mse: 1.1049\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1046 - mse: 1.1046\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1042 - mse: 1.1042\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1038 - mse: 1.1038\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1035 - mse: 1.1035\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1031 - mse: 1.1031\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1028 - mse: 1.1028\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1024 - mse: 1.1024\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1021 - mse: 1.1021\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1017 - mse: 1.1017\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1014 - mse: 1.1014\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1010 - mse: 1.1010\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1007 - mse: 1.1007\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1004 - mse: 1.1004\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1000 - mse: 1.1000\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0997 - mse: 1.0997\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0994 - mse: 1.0994\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0991 - mse: 1.0991\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0987 - mse: 1.0987\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0984 - mse: 1.0984\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0981 - mse: 1.0981\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0978 - mse: 1.0978\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0975 - mse: 1.0975\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0972 - mse: 1.0972\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0969 - mse: 1.0969\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0966 - mse: 1.0966\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0963 - mse: 1.0963\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0960 - mse: 1.0960\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0957 - mse: 1.0957\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0954 - mse: 1.0954\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0951 - mse: 1.0951\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0948 - mse: 1.0948\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0945 - mse: 1.0945\n",
      "Epoch 173/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0942 - mse: 1.0942\n",
      "Epoch 174/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0939 - mse: 1.0939\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0937 - mse: 1.0937\n",
      "Epoch 176/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0934 - mse: 1.0934\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0931 - mse: 1.0931\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0928 - mse: 1.0928\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0926 - mse: 1.0926\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0923 - mse: 1.0923\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0920 - mse: 1.0920\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0918 - mse: 1.0918\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0915 - mse: 1.0915\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0912 - mse: 1.0912\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0910 - mse: 1.0910\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0907 - mse: 1.0907\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0905 - mse: 1.0905\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0902 - mse: 1.0902\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0900 - mse: 1.0900\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0897 - mse: 1.0897\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0895 - mse: 1.0895\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0893 - mse: 1.0893\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0890 - mse: 1.0890\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0888 - mse: 1.0888\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0885 - mse: 1.0885\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0883 - mse: 1.0883\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0881 - mse: 1.0881\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0878 - mse: 1.0878\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0876 - mse: 1.0876\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0874 - mse: 1.0874\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0872 - mse: 1.0872\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0869 - mse: 1.0869\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0867 - mse: 1.0867\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0865 - mse: 1.0865\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0863 - mse: 1.0863\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0861 - mse: 1.0861\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0858 - mse: 1.0858\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0856 - mse: 1.0856\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0854 - mse: 1.0854\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0852 - mse: 1.0852\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0850 - mse: 1.0850\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0848 - mse: 1.0848\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0846 - mse: 1.0846\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0844 - mse: 1.0844\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0842 - mse: 1.0842\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0840 - mse: 1.0840\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0838 - mse: 1.0838\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0836 - mse: 1.0836\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0834 - mse: 1.0834\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0832 - mse: 1.0832\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0830 - mse: 1.0830\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0828 - mse: 1.0828\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0826 - mse: 1.0826\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0824 - mse: 1.0824\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0823 - mse: 1.0823\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0821 - mse: 1.0821\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0819 - mse: 1.0819\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0817 - mse: 1.0817\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0815 - mse: 1.0815\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0814 - mse: 1.0814\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0812 - mse: 1.0812\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0810 - mse: 1.0810\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0808 - mse: 1.0808\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0807 - mse: 1.0807\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0805 - mse: 1.0805\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0803 - mse: 1.0803\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0802 - mse: 1.0802\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0800 - mse: 1.0800\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0798 - mse: 1.0798\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0797 - mse: 1.0797\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0795 - mse: 1.0795\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0793 - mse: 1.0793\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0792 - mse: 1.0792\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0790 - mse: 1.0790\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0789 - mse: 1.0789\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0787 - mse: 1.0787\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0786 - mse: 1.0786\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0784 - mse: 1.0784\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0782 - mse: 1.0782\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0781 - mse: 1.0781\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0779 - mse: 1.0779\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0778 - mse: 1.0778\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0777 - mse: 1.0777\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0775 - mse: 1.0775\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0774 - mse: 1.0774\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0772 - mse: 1.0772\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0771 - mse: 1.0771\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0769 - mse: 1.0769\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0768 - mse: 1.0768\n",
      "Epoch 260/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0767 - mse: 1.0767\n",
      "Epoch 261/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0765 - mse: 1.0765\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0764 - mse: 1.0764\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0762 - mse: 1.0762\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0761 - mse: 1.0761\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0760 - mse: 1.0760\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0758 - mse: 1.0758\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0757 - mse: 1.0757\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0756 - mse: 1.0756\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0755 - mse: 1.0755\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0753 - mse: 1.0753\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0752 - mse: 1.0752\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0751 - mse: 1.0751\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0750 - mse: 1.0750\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0748 - mse: 1.0748\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0747 - mse: 1.0747\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0746 - mse: 1.0746\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0745 - mse: 1.0745\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0743 - mse: 1.0743\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0742 - mse: 1.0742\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0741 - mse: 1.0741\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0740 - mse: 1.0740\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0739 - mse: 1.0739\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0738 - mse: 1.0738\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0736 - mse: 1.0736\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0735 - mse: 1.0735\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0734 - mse: 1.0734\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0733 - mse: 1.0733\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0732 - mse: 1.0732\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0731 - mse: 1.0731\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0730 - mse: 1.0730\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0729 - mse: 1.0729\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0728 - mse: 1.0728\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0727 - mse: 1.0727\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0726 - mse: 1.0726\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0725 - mse: 1.0725\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0724 - mse: 1.0724\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0723 - mse: 1.0723\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0721 - mse: 1.0721\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0720 - mse: 1.0720\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0720 - mse: 1.0720\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2 (8.00 Byte)\n",
      "Trainable params: 2 (8.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 43.625763],\n",
       "       [107.49836 ],\n",
       "       [118.14379 ]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linear regression - Functional api\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "X = [1, 2, 3, 4, 5, 6, 7, 8, 9] # 공부시간\n",
    "y = [11, 22, 33, 44, 53, 66, 77, 87, 95] # 각 공부하는 시간에 맵핑되는 성적\n",
    "\n",
    "inputs = Input(shape=(1,))\n",
    "output = Dense(1, activation='linear')(inputs)\n",
    "linear_model = Model(inputs, output)\n",
    "\n",
    "sgd = optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "linear_model.compile(optimizer=sgd, loss='mse', metrics=['mse'])\n",
    "linear_model.fit(X, y, epochs=300)\n",
    "\n",
    "linear_model.summary()\n",
    "# W,b 2개라서 parameter 2개\n",
    "\n",
    "linear_model.predict([4, 10, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ae325ec3-022a-455c-b983-704c926db580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3742 - binary_accuracy: 0.9231\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3727 - binary_accuracy: 0.9231\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3712 - binary_accuracy: 0.9231\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3697 - binary_accuracy: 0.9231\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3681 - binary_accuracy: 0.9231\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3666 - binary_accuracy: 0.9231\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3651 - binary_accuracy: 0.9231\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3636 - binary_accuracy: 0.9231\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3621 - binary_accuracy: 0.9231\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3606 - binary_accuracy: 0.9231\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3591 - binary_accuracy: 0.9231\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3576 - binary_accuracy: 0.9231\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3561 - binary_accuracy: 0.9231\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3546 - binary_accuracy: 0.9231\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3531 - binary_accuracy: 0.9231\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3516 - binary_accuracy: 0.9231\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3502 - binary_accuracy: 0.9231\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3487 - binary_accuracy: 0.9231\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3472 - binary_accuracy: 0.9231\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3457 - binary_accuracy: 0.9231\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3442 - binary_accuracy: 0.9231\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3428 - binary_accuracy: 0.9231\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3413 - binary_accuracy: 0.9231\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3398 - binary_accuracy: 0.9231\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3384 - binary_accuracy: 0.9231\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3369 - binary_accuracy: 0.9231\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3354 - binary_accuracy: 0.9231\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3340 - binary_accuracy: 0.9231\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3325 - binary_accuracy: 0.9231\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3311 - binary_accuracy: 0.9231\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3296 - binary_accuracy: 0.9231\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3282 - binary_accuracy: 0.9231\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3267 - binary_accuracy: 0.9231\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3253 - binary_accuracy: 0.9231\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3239 - binary_accuracy: 0.9231\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3224 - binary_accuracy: 0.9231\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3210 - binary_accuracy: 0.9231\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3196 - binary_accuracy: 0.9231\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3181 - binary_accuracy: 0.9231\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3167 - binary_accuracy: 0.9231\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3153 - binary_accuracy: 0.9231\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3139 - binary_accuracy: 0.9231\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3125 - binary_accuracy: 0.9231\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3111 - binary_accuracy: 0.9231\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3097 - binary_accuracy: 0.9231\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3083 - binary_accuracy: 0.9231\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3069 - binary_accuracy: 0.9231\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3055 - binary_accuracy: 0.9231\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3041 - binary_accuracy: 0.9231\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3027 - binary_accuracy: 0.9231\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3013 - binary_accuracy: 0.9231\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3000 - binary_accuracy: 0.9231\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2986 - binary_accuracy: 0.9231\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2972 - binary_accuracy: 0.9231\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2959 - binary_accuracy: 0.9231\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2945 - binary_accuracy: 0.9231\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2932 - binary_accuracy: 0.9231\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2918 - binary_accuracy: 0.9231\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2905 - binary_accuracy: 0.9231\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2891 - binary_accuracy: 0.9231\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2878 - binary_accuracy: 0.9231\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2865 - binary_accuracy: 0.9231\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2852 - binary_accuracy: 0.9231\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2838 - binary_accuracy: 0.9231\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2825 - binary_accuracy: 0.9231\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2812 - binary_accuracy: 0.9231\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2799 - binary_accuracy: 0.9231\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2786 - binary_accuracy: 0.9231\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2773 - binary_accuracy: 0.9231\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2760 - binary_accuracy: 0.9231\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2748 - binary_accuracy: 0.9231\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2735 - binary_accuracy: 0.9231\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2722 - binary_accuracy: 0.9231\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2709 - binary_accuracy: 0.9231\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2697 - binary_accuracy: 0.9231\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2684 - binary_accuracy: 0.9231\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2672 - binary_accuracy: 0.9231\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2660 - binary_accuracy: 0.9231\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2647 - binary_accuracy: 0.9231\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2635 - binary_accuracy: 0.9231\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2623 - binary_accuracy: 0.9231\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2611 - binary_accuracy: 0.9231\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2599 - binary_accuracy: 0.9231\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2587 - binary_accuracy: 0.9231\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2575 - binary_accuracy: 0.9231\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2563 - binary_accuracy: 0.9231\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2551 - binary_accuracy: 0.9231\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2539 - binary_accuracy: 0.9231\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2528 - binary_accuracy: 0.9231\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2516 - binary_accuracy: 0.9231\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2504 - binary_accuracy: 0.9231\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2493 - binary_accuracy: 0.9231\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2482 - binary_accuracy: 0.9231\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2470 - binary_accuracy: 0.9231\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2459 - binary_accuracy: 0.9231\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2448 - binary_accuracy: 0.9231\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2437 - binary_accuracy: 0.9231\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2426 - binary_accuracy: 0.9231\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2415 - binary_accuracy: 0.9231\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2404 - binary_accuracy: 0.9231\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2394 - binary_accuracy: 0.9231\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2383 - binary_accuracy: 0.9231\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2372 - binary_accuracy: 0.9231\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2362 - binary_accuracy: 0.9231\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2351 - binary_accuracy: 0.9231\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2341 - binary_accuracy: 0.9231\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2331 - binary_accuracy: 0.9231\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2321 - binary_accuracy: 0.9231\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2311 - binary_accuracy: 0.9231\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2301 - binary_accuracy: 0.9231\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2291 - binary_accuracy: 0.9231\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2281 - binary_accuracy: 0.9231\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2271 - binary_accuracy: 0.9231\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2262 - binary_accuracy: 0.9231\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2252 - binary_accuracy: 0.9231\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2243 - binary_accuracy: 0.9231\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2233 - binary_accuracy: 0.9231\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2224 - binary_accuracy: 0.9231\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2215 - binary_accuracy: 0.9231\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2206 - binary_accuracy: 0.9231\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2197 - binary_accuracy: 0.9231\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2188 - binary_accuracy: 0.9231\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2179 - binary_accuracy: 0.9231\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2171 - binary_accuracy: 0.9231\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2162 - binary_accuracy: 0.9231\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2154 - binary_accuracy: 0.9231\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2145 - binary_accuracy: 0.9231\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2137 - binary_accuracy: 0.9231\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2129 - binary_accuracy: 0.9231\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2121 - binary_accuracy: 0.9231\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2113 - binary_accuracy: 0.9231\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2105 - binary_accuracy: 0.9231\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2097 - binary_accuracy: 0.9231\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2090 - binary_accuracy: 0.9231\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2082 - binary_accuracy: 0.9231\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2075 - binary_accuracy: 0.9231\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2067 - binary_accuracy: 0.9231\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2060 - binary_accuracy: 0.9231\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2053 - binary_accuracy: 0.9231\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2046 - binary_accuracy: 0.9231\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2039 - binary_accuracy: 0.9231\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2032 - binary_accuracy: 0.9231\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2025 - binary_accuracy: 0.9231\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2019 - binary_accuracy: 0.9231\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2012 - binary_accuracy: 0.9231\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2006 - binary_accuracy: 0.9231\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1999 - binary_accuracy: 0.9231\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1993 - binary_accuracy: 0.9231\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1987 - binary_accuracy: 0.9231\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1981 - binary_accuracy: 0.9231\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1975 - binary_accuracy: 0.9231\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1969 - binary_accuracy: 0.9231\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1963 - binary_accuracy: 0.9231\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1958 - binary_accuracy: 0.9231\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1952 - binary_accuracy: 0.9231\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1947 - binary_accuracy: 0.9231\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1941 - binary_accuracy: 0.9231\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1936 - binary_accuracy: 0.9231\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1931 - binary_accuracy: 0.9231\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1926 - binary_accuracy: 0.9231\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1921 - binary_accuracy: 0.9231\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1916 - binary_accuracy: 0.9231\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1911 - binary_accuracy: 0.9231\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1907 - binary_accuracy: 0.9231\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1902 - binary_accuracy: 0.9231\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1897 - binary_accuracy: 0.9231\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1893 - binary_accuracy: 0.9231\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1889 - binary_accuracy: 0.9231\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1884 - binary_accuracy: 0.9231\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1880 - binary_accuracy: 0.9231\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1876 - binary_accuracy: 0.9231\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1872 - binary_accuracy: 0.9231\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1868 - binary_accuracy: 0.9231\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1864 - binary_accuracy: 0.9231\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1861 - binary_accuracy: 0.9231\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1857 - binary_accuracy: 0.9231\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1853 - binary_accuracy: 0.9231\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1850 - binary_accuracy: 0.9231\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1846 - binary_accuracy: 0.9231\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1843 - binary_accuracy: 0.9231\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1840 - binary_accuracy: 0.9231\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1837 - binary_accuracy: 0.9231\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1833 - binary_accuracy: 0.9231\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1830 - binary_accuracy: 0.9231\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1827 - binary_accuracy: 0.9231\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1824 - binary_accuracy: 0.9231\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1821 - binary_accuracy: 0.9231\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1819 - binary_accuracy: 0.9231\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1816 - binary_accuracy: 0.9231\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1813 - binary_accuracy: 0.9231\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1810 - binary_accuracy: 0.9231\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1808 - binary_accuracy: 0.9231\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1805 - binary_accuracy: 0.9231\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1803 - binary_accuracy: 0.9231\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1800 - binary_accuracy: 0.9231\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1798 - binary_accuracy: 0.9231\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1796 - binary_accuracy: 0.9231\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1793 - binary_accuracy: 0.9231\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1791 - binary_accuracy: 0.9231\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1789 - binary_accuracy: 0.9231\n",
      "Model: \"model_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_44 (InputLayer)       [(None, 1)]               0         \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2 (8.00 Byte)\n",
      "Trainable params: 2 (8.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f773428de40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 35ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.01463854],\n",
       "       [0.999992  ]], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "import numpy as np\n",
    "\n",
    "# logistic regression\n",
    "x = np.array([-50, -40, -30, -20, -10, -5, 0, 5, 10, 20, 30, 40, 50])\n",
    "y = np.array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]) # 숫자 10부터 1\n",
    "\n",
    "inputs = Input(shape=(1,))\n",
    "output = Dense(1, activation='sigmoid')(inputs)\n",
    "logistic_model = Model(inputs, output)\n",
    "\n",
    "sgd = optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "logistic_model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "\n",
    "logistic_model.fit(x, y, epochs=200)\n",
    "\n",
    "logistic_model.summary()\n",
    "\n",
    "logistic_model.predict([-15, 45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6a2e4c05-795b-4c97-9240-4c92ec5c26c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중입력 모델 (ex: Model(inputs=[a1, a2], outputs=[b1, b2, b3]))\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# 두개의 입력층 정의\n",
    "inputA = Input(shape=(64,))\n",
    "inputB = Input(shape=(128,))\n",
    "\n",
    "# 첫번째 입력층으로부터 분기되는 인공신경망 정의\n",
    "x = Dense(16, activation=\"relu\")(inputA)\n",
    "x = Dense(8, activation=\"relu\")(x)\n",
    "x = Model(inputs=inputA, outputs=x)\n",
    "\n",
    "# 두번째 정의\n",
    "y = Dense(64, activation=\"relu\")(inputB)\n",
    "y = Dense(32, activation=\"relu\")(y)\n",
    "y = Dense(8, activation=\"relu\")(y)\n",
    "y = Model(inputs=inputB, outputs=y)\n",
    "\n",
    "# 두개의 신경망의 출력 연결\n",
    "result = concatenate([x.output, y.output])\n",
    "\n",
    "z = Dense(2, activation=\"relu\")(result)\n",
    "z = Dense(1, activation=\"linear\")(z)\n",
    "\n",
    "model = Model(inputs=[x.input, y.input], outputs=z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bae233db-09ce-41cd-b370-b9066a4f4fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RNN\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# 하나의 특성에 50개의 시점을 입력\n",
    "inputs = Input(shape=(50,1))\n",
    "lstm_layer = LSTM(10)(inputs)\n",
    "x = Dense(10, activation='relu')(lstm_layer)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
