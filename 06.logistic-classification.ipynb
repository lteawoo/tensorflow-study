{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dea1790-0bbd-4043-8fd0-ae9e1b3f966d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tf.Tensor(1.8380541, shape=(), dtype=float32)\n",
      "200 tf.Tensor(0.46197116, shape=(), dtype=float32)\n",
      "400 tf.Tensor(0.44029394, shape=(), dtype=float32)\n",
      "600 tf.Tensor(0.4225897, shape=(), dtype=float32)\n",
      "800 tf.Tensor(0.40708897, shape=(), dtype=float32)\n",
      "1000 tf.Tensor(0.3930001, shape=(), dtype=float32)\n",
      "1200 tf.Tensor(0.37992963, shape=(), dtype=float32)\n",
      "1400 tf.Tensor(0.36766735, shape=(), dtype=float32)\n",
      "1600 tf.Tensor(0.35609207, shape=(), dtype=float32)\n",
      "1800 tf.Tensor(0.3451271, shape=(), dtype=float32)\n",
      "2000 tf.Tensor(0.33471894, shape=(), dtype=float32)\n",
      "2200 tf.Tensor(0.3248271, shape=(), dtype=float32)\n",
      "2400 tf.Tensor(0.31541798, shape=(), dtype=float32)\n",
      "2600 tf.Tensor(0.30646226, shape=(), dtype=float32)\n",
      "2800 tf.Tensor(0.29793343, shape=(), dtype=float32)\n",
      "3000 tf.Tensor(0.2898072, shape=(), dtype=float32)\n",
      "3200 tf.Tensor(0.28206056, shape=(), dtype=float32)\n",
      "3400 tf.Tensor(0.27467203, shape=(), dtype=float32)\n",
      "3600 tf.Tensor(0.26762125, shape=(), dtype=float32)\n",
      "3800 tf.Tensor(0.26088917, shape=(), dtype=float32)\n",
      "4000 tf.Tensor(0.25445774, shape=(), dtype=float32)\n",
      "4200 tf.Tensor(0.2483099, shape=(), dtype=float32)\n",
      "4400 tf.Tensor(0.24242981, shape=(), dtype=float32)\n",
      "4600 tf.Tensor(0.23680234, shape=(), dtype=float32)\n",
      "4800 tf.Tensor(0.23141354, shape=(), dtype=float32)\n",
      "5000 tf.Tensor(0.22624993, shape=(), dtype=float32)\n",
      "5200 tf.Tensor(0.22129916, shape=(), dtype=float32)\n",
      "5400 tf.Tensor(0.21654959, shape=(), dtype=float32)\n",
      "5600 tf.Tensor(0.21199031, shape=(), dtype=float32)\n",
      "5800 tf.Tensor(0.20761102, shape=(), dtype=float32)\n",
      "6000 tf.Tensor(0.20340212, shape=(), dtype=float32)\n",
      "6200 tf.Tensor(0.19935463, shape=(), dtype=float32)\n",
      "6400 tf.Tensor(0.1954601, shape=(), dtype=float32)\n",
      "6600 tf.Tensor(0.19171049, shape=(), dtype=float32)\n",
      "6800 tf.Tensor(0.1880985, shape=(), dtype=float32)\n",
      "7000 tf.Tensor(0.18461709, shape=(), dtype=float32)\n",
      "7200 tf.Tensor(0.18125969, shape=(), dtype=float32)\n",
      "7400 tf.Tensor(0.17802012, shape=(), dtype=float32)\n",
      "7600 tf.Tensor(0.17489262, shape=(), dtype=float32)\n",
      "7800 tf.Tensor(0.17187177, shape=(), dtype=float32)\n",
      "8000 tf.Tensor(0.16895245, shape=(), dtype=float32)\n",
      "8200 tf.Tensor(0.16612977, shape=(), dtype=float32)\n",
      "8400 tf.Tensor(0.16339932, shape=(), dtype=float32)\n",
      "8600 tf.Tensor(0.16075675, shape=(), dtype=float32)\n",
      "8800 tf.Tensor(0.15819807, shape=(), dtype=float32)\n",
      "9000 tf.Tensor(0.15571947, shape=(), dtype=float32)\n",
      "9200 tf.Tensor(0.1533174, shape=(), dtype=float32)\n",
      "9400 tf.Tensor(0.15098837, shape=(), dtype=float32)\n",
      "9600 tf.Tensor(0.1487294, shape=(), dtype=float32)\n",
      "9800 tf.Tensor(0.14653717, shape=(), dtype=float32)\n",
      "10000 tf.Tensor(0.1444091, shape=(), dtype=float32)\n",
      "Hypothesis:  tf.Tensor(\n",
      "[[0.02863405]\n",
      " [0.1558898 ]\n",
      " [0.29462716]\n",
      " [0.78610003]\n",
      " [0.9425098 ]\n",
      " [0.9811584 ]], shape=(6, 1), dtype=float32) \n",
      "Correct (Y):  tf.Tensor(0.1444091, shape=(), dtype=float32) \n",
      "Accuracy:  tf.Tensor(1.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x_data = tf.constant([[1, 2],\n",
    "                      [2, 3],\n",
    "                      [3, 1],\n",
    "                      [4, 3],\n",
    "                      [5, 3],\n",
    "                      [6, 2]], dtype=tf.float32)\n",
    "y_data = tf.constant([[0],\n",
    "                      [0],\n",
    "                      [0],\n",
    "                      [1],\n",
    "                      [1],\n",
    "                      [1]], dtype=tf.float32)\n",
    "\n",
    "X = tf.Variable(0., shape=tf.TensorShape(None), dtype = tf.float32)\n",
    "Y = tf.Variable(0., shape=tf.TensorShape(None), dtype = tf.float32)\n",
    "W = tf.Variable(tf.random.normal([2, 1]), name='weight')\n",
    "b = tf.Variable(tf.random.normal([1]), name='bias')\n",
    "\n",
    "# sigmoid function == tf.math.div(1. 1. + tf.math.exp(tf.linalg.matmul(X, W) + b))\n",
    "def hypothesis():\n",
    "    return tf.sigmoid(tf.linalg.matmul(X, W) + b)\n",
    "\n",
    "# 밥그릇 형태를 위한 2가지 로그함수 짬뽕 (Y값이 1과 0을 표현해야하므로)\n",
    "def cost(): \n",
    "    return -tf.reduce_mean(Y * tf.math.log(hypothesis()) + (1 - Y) * tf.math.log(1 - hypothesis()))\n",
    "\n",
    "# 경사하강법\n",
    "def train():\n",
    "    return tf.keras.optimizers.SGD(learning_rate = 0.01).minimize(cost, var_list=[W, b])\n",
    "\n",
    "# Hypothesis가 0.5 보다 크면 true, 외 false 처리하기 위해 float32로 캐스팅\n",
    "def predicted():\n",
    "    return tf.cast(hypothesis() > 0.5, dtype=tf.float32)\n",
    "\n",
    "# 정확도 계산, 예측값과 실 Y값이 얼마나 같은지를 평균\n",
    "def accuracy():\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(predicted(), Y), dtype=tf.float32))\n",
    "\n",
    "X.assign(x_data)\n",
    "Y.assign(y_data)\n",
    "for step in range(10001):\n",
    "    train()\n",
    "    if step % 200 == 0:\n",
    "        print(step, cost())\n",
    "\n",
    "h, c, a = hypothesis(), cost(), accuracy()\n",
    "print(\"Hypothesis: \", h, \"\\nCorrect (Y): \", c, \"\\nAccuracy: \", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5084ea4a-acc9-4f8e-b54c-e780108b3c77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3 (12.00 Byte)\n",
      "Trainable params: 3 (12.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "200/200 [==============================] - 0s 648us/step - loss: 0.5256 - accuracy: 0.8350\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 0s 617us/step - loss: 0.4973 - accuracy: 0.8350\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 0s 602us/step - loss: 0.4810 - accuracy: 0.8350\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 0s 611us/step - loss: 0.4684 - accuracy: 0.8300\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 0s 596us/step - loss: 0.4467 - accuracy: 0.8350\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 0s 596us/step - loss: 0.4355 - accuracy: 0.8300\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 0s 598us/step - loss: 0.4218 - accuracy: 0.8300\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 0s 606us/step - loss: 0.4071 - accuracy: 0.8300\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 0s 622us/step - loss: 0.3933 - accuracy: 0.8300\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 0s 613us/step - loss: 0.3743 - accuracy: 0.8350\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 0s 599us/step - loss: 0.3683 - accuracy: 0.8300\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 0s 587us/step - loss: 0.3519 - accuracy: 0.8350\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 0s 599us/step - loss: 0.3411 - accuracy: 0.8350\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 0s 607us/step - loss: 0.3309 - accuracy: 0.8350\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 0s 670us/step - loss: 0.3240 - accuracy: 0.8300\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 0s 604us/step - loss: 0.3106 - accuracy: 0.8350\n",
      "Epoch 17/50\n",
      "200/200 [==============================] - 0s 604us/step - loss: 0.3013 - accuracy: 0.8350\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 0s 607us/step - loss: 0.2931 - accuracy: 0.8350\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 0s 619us/step - loss: 0.2863 - accuracy: 0.8350\n",
      "Epoch 20/50\n",
      "200/200 [==============================] - 0s 616us/step - loss: 0.2792 - accuracy: 0.8350\n",
      "Epoch 21/50\n",
      "200/200 [==============================] - 0s 629us/step - loss: 0.2715 - accuracy: 0.8350\n",
      "Epoch 22/50\n",
      "200/200 [==============================] - 0s 677us/step - loss: 0.2644 - accuracy: 0.8350\n",
      "Epoch 23/50\n",
      "200/200 [==============================] - 0s 626us/step - loss: 0.2589 - accuracy: 0.8700\n",
      "Epoch 24/50\n",
      "200/200 [==============================] - 0s 629us/step - loss: 0.2510 - accuracy: 0.9250\n",
      "Epoch 25/50\n",
      "200/200 [==============================] - 0s 612us/step - loss: 0.2488 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "200/200 [==============================] - 0s 606us/step - loss: 0.2417 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "200/200 [==============================] - 0s 608us/step - loss: 0.2329 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "200/200 [==============================] - 0s 616us/step - loss: 0.2318 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "200/200 [==============================] - 0s 610us/step - loss: 0.2252 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "200/200 [==============================] - 0s 625us/step - loss: 0.2202 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "200/200 [==============================] - 0s 628us/step - loss: 0.2131 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "200/200 [==============================] - 0s 620us/step - loss: 0.2087 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "200/200 [==============================] - 0s 608us/step - loss: 0.2062 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "200/200 [==============================] - 0s 611us/step - loss: 0.2026 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "200/200 [==============================] - 0s 623us/step - loss: 0.1996 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "200/200 [==============================] - 0s 613us/step - loss: 0.1932 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "200/200 [==============================] - 0s 617us/step - loss: 0.1914 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "200/200 [==============================] - 0s 623us/step - loss: 0.1862 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "200/200 [==============================] - 0s 607us/step - loss: 0.1815 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "200/200 [==============================] - 0s 603us/step - loss: 0.1803 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "200/200 [==============================] - 0s 621us/step - loss: 0.1752 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "200/200 [==============================] - 0s 628us/step - loss: 0.1739 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "200/200 [==============================] - 0s 608us/step - loss: 0.1692 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "200/200 [==============================] - 0s 630us/step - loss: 0.1673 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "200/200 [==============================] - 0s 615us/step - loss: 0.1643 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "200/200 [==============================] - 0s 623us/step - loss: 0.1607 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "200/200 [==============================] - 0s 610us/step - loss: 0.1593 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "200/200 [==============================] - 0s 596us/step - loss: 0.1574 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "200/200 [==============================] - 0s 597us/step - loss: 0.1541 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "200/200 [==============================] - 0s 606us/step - loss: 0.1536 - accuracy: 1.0000\n",
      "Accuracy:  1.0\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Predict:  [[0.03082051]\n",
      " [0.16144317]\n",
      " [0.30494657]\n",
      " [0.7862682 ]\n",
      " [0.9414548 ]\n",
      " [0.9806779 ]]\n"
     ]
    }
   ],
   "source": [
    "# Lab 5 Logistic Regression Classifier\n",
    "import tensorflow as tf\n",
    "\n",
    "x_data = [[1, 2],\n",
    "          [2, 3],\n",
    "          [3, 1],\n",
    "          [4, 3],\n",
    "          [5, 3],\n",
    "          [6, 2]]\n",
    "y_data = [[0],\n",
    "          [0],\n",
    "          [0],\n",
    "          [1],\n",
    "          [1],\n",
    "          [1]]\n",
    "\n",
    "tf.model = tf.keras.Sequential()\n",
    "tf.model.add(tf.keras.layers.Dense(units=1, input_dim=2))\n",
    "# use sigmoid activation for 0~1 problem\n",
    "tf.model.add(tf.keras.layers.Activation('sigmoid'))\n",
    "\n",
    "''' \n",
    "better result with loss function == 'binary_crossentropy', try 'mse' for yourself\n",
    "adding accuracy metric to get accuracy report during training\n",
    "'''\n",
    "tf.model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.SGD(learning_rate=0.01), metrics=['accuracy'])\n",
    "tf.model.summary()\n",
    "\n",
    "history = tf.model.fit(x_data, y_data, epochs=50, steps_per_epoch=200)\n",
    "\n",
    "# Accuracy report\n",
    "print(\"Accuracy: \", history.history['accuracy'][-1])\n",
    "\n",
    "# predict\n",
    "print(\"Predict: \", tf.model.predict(x_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0afa900-f796-4c81-bf77-d50105703a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 Cost:  2.0653427\n",
      "0 200 Cost:  0.91490465\n",
      "0 400 Cost:  0.6127531\n",
      "0 600 Cost:  0.5562735\n",
      "0 800 Cost:  0.5404971\n",
      "0 1000 Cost:  0.53240657\n",
      "0 1200 Cost:  0.5263992\n",
      "0 1400 Cost:  0.5213564\n",
      "0 1600 Cost:  0.51698375\n",
      "0 1800 Cost:  0.51315624\n",
      "0 2000 Cost:  0.5097928\n",
      "1 0 Cost:  0.5932235\n",
      "1 200 Cost:  0.57819104\n",
      "1 400 Cost:  0.56632\n",
      "1 600 Cost:  0.55586517\n",
      "1 800 Cost:  0.5463861\n",
      "1 1000 Cost:  0.5377217\n",
      "1 1200 Cost:  0.52977437\n",
      "1 1400 Cost:  0.522467\n",
      "1 1600 Cost:  0.5157332\n",
      "1 1800 Cost:  0.50951445\n",
      "1 2000 Cost:  0.5037594\n",
      "2 0 Cost:  0.57251334\n",
      "2 200 Cost:  0.57106435\n",
      "2 400 Cost:  0.5700434\n",
      "2 600 Cost:  0.5691752\n",
      "2 800 Cost:  0.56839544\n",
      "2 1000 Cost:  0.56768465\n",
      "2 1200 Cost:  0.5670336\n",
      "2 1400 Cost:  0.56643575\n",
      "2 1600 Cost:  0.5658855\n",
      "2 1800 Cost:  0.5653779\n",
      "2 2000 Cost:  0.5649086\n",
      "3 0 Cost:  0.50466937\n",
      "3 200 Cost:  0.498627\n",
      "3 400 Cost:  0.4942278\n",
      "3 600 Cost:  0.49046153\n",
      "3 800 Cost:  0.48709682\n",
      "3 1000 Cost:  0.4840528\n",
      "3 1200 Cost:  0.4812825\n",
      "3 1400 Cost:  0.47874978\n",
      "3 1600 Cost:  0.47642508\n",
      "3 1800 Cost:  0.47428337\n",
      "3 2000 Cost:  0.47230324\n",
      "4 0 Cost:  0.49658325\n",
      "4 200 Cost:  0.4757678\n",
      "4 400 Cost:  0.46966457\n",
      "4 600 Cost:  0.46715695\n",
      "4 800 Cost:  0.46561393\n",
      "4 1000 Cost:  0.4643646\n",
      "4 1200 Cost:  0.46322918\n",
      "4 1400 Cost:  0.462157\n",
      "4 1600 Cost:  0.46113214\n",
      "4 1800 Cost:  0.46014825\n",
      "4 2000 Cost:  0.45920166\n",
      "5 0 Cost:  0.36286643\n",
      "5 200 Cost:  0.35883513\n",
      "5 400 Cost:  0.355243\n",
      "5 600 Cost:  0.35197553\n",
      "5 800 Cost:  0.34897816\n",
      "5 1000 Cost:  0.34621656\n",
      "5 1200 Cost:  0.34366444\n",
      "5 1400 Cost:  0.3413\n",
      "5 1600 Cost:  0.33910456\n",
      "5 1800 Cost:  0.33706164\n",
      "5 2000 Cost:  0.33515668\n",
      "6 0 Cost:  0.49251857\n",
      "6 200 Cost:  0.48787162\n",
      "6 400 Cost:  0.4849192\n",
      "6 600 Cost:  0.48254997\n",
      "6 800 Cost:  0.4804593\n",
      "6 1000 Cost:  0.47855607\n",
      "6 1200 Cost:  0.47680518\n",
      "6 1400 Cost:  0.47518718\n",
      "6 1600 Cost:  0.47368774\n",
      "6 1800 Cost:  0.47229496\n",
      "6 2000 Cost:  0.47099847\n",
      "7 0 Cost:  0.4781737\n",
      "7 200 Cost:  0.47010177\n",
      "7 400 Cost:  0.4660003\n",
      "7 600 Cost:  0.46300736\n",
      "7 800 Cost:  0.4604022\n",
      "7 1000 Cost:  0.45800322\n",
      "7 1200 Cost:  0.45575896\n",
      "7 1400 Cost:  0.45364916\n",
      "7 1600 Cost:  0.45166153\n",
      "7 1800 Cost:  0.44978634\n",
      "7 2000 Cost:  0.44801515\n",
      "Hypothesis:  tf.Tensor(\n",
      "[[0.851403  ]\n",
      " [0.4551556 ]\n",
      " [0.80048066]\n",
      " [0.25530782]\n",
      " [0.58512384]\n",
      " [0.8530102 ]\n",
      " [0.07996375]\n",
      " [0.25109512]\n",
      " [0.82395035]\n",
      " [0.82150763]\n",
      " [0.70394516]\n",
      " [0.92029965]\n",
      " [0.679431  ]\n",
      " [0.64813095]\n",
      " [0.69286513]\n",
      " [0.75355506]\n",
      " [0.5854517 ]\n",
      " [0.7897127 ]\n",
      " [0.46872512]\n",
      " [0.492587  ]\n",
      " [0.8937783 ]\n",
      " [0.82804835]\n",
      " [0.7365324 ]\n",
      " [0.18620317]\n",
      " [0.90220344]\n",
      " [0.83922935]\n",
      " [0.7946027 ]\n",
      " [0.7222894 ]\n",
      " [0.8933308 ]\n",
      " [0.797468  ]\n",
      " [0.67437017]\n",
      " [0.3505618 ]\n",
      " [0.89813524]\n",
      " [0.9256645 ]\n",
      " [0.31660584]\n",
      " [0.1424121 ]\n",
      " [0.8154057 ]\n",
      " [0.20555964]\n",
      " [0.78957397]\n",
      " [0.17426793]\n",
      " [0.36844608]\n",
      " [0.44856033]\n",
      " [0.76144123]\n",
      " [0.8749636 ]\n",
      " [0.06370769]\n",
      " [0.26632893]\n",
      " [0.616093  ]\n",
      " [0.4682393 ]\n",
      " [0.39574274]\n",
      " [0.75203264]\n",
      " [0.06575041]\n",
      " [0.95374113]\n",
      " [0.06573617]\n",
      " [0.9091566 ]\n",
      " [0.7244521 ]\n",
      " [0.61974454]\n",
      " [0.87554896]\n",
      " [0.62257   ]\n",
      " [0.9024183 ]], shape=(59, 1), dtype=float32) \n",
      "Correct (Y):  tf.Tensor(0.44801515, shape=(), dtype=float32) \n",
      "Accuracy:  tf.Tensor(0.779661, shape=(), dtype=float32)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Predict: [[0.6079865]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 당뇨병 예측 데이터 1~8->팩터, 9->당뇨X: 0 당뇨Y: 1\n",
    "dataset = tf.data.experimental.make_csv_dataset('resource/data-03-diabetes.csv', batch_size=100, num_epochs=1, shuffle=False, header=False, column_names=[1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "X = tf.Variable(1., dtype=tf.float32, shape=tf.TensorShape(None))\n",
    "Y = tf.Variable(1., dtype=tf.float32, shape=tf.TensorShape(None))\n",
    "\n",
    "W = tf.Variable(tf.random.normal([8, 1]), name='weight')\n",
    "b = tf.Variable(tf.random.normal([1]), name='bias')\n",
    "\n",
    "# sigmoid function == tf.math.div(1. 1. + tf.math.exp(tf.linalg.matmul(X, W) + b))\n",
    "def hypothesis():\n",
    "    return tf.sigmoid(tf.linalg.matmul(X, W) + b)\n",
    "\n",
    "# 밥그릇 형태를 위한 2가지 로그함수 짬뽕 (Y값이 1과 0을 표현해야하므로)\n",
    "def cost(): \n",
    "    return -tf.reduce_mean(Y * tf.math.log(hypothesis()) + (1 - Y) * tf.math.log(1 - hypothesis()))\n",
    "\n",
    "# 경사하강법\n",
    "def train():\n",
    "    return tf.keras.optimizers.SGD(learning_rate = 0.01).minimize(cost, var_list=[W, b])\n",
    "\n",
    "# Hypothesis가 0.5 보다 크면 true, 외 false 처리하기 위해 float32로 캐스팅\n",
    "def predicted():\n",
    "    return tf.cast(hypothesis() > 0.5, dtype=tf.float32)\n",
    "\n",
    "# 정확도 계산, 예측값과 실 Y값이 얼마나 같은지를 평균\n",
    "def accuracy():\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(predicted(), Y), dtype=tf.float32))\n",
    "\n",
    "i = 0\n",
    "for dict in dataset.as_numpy_iterator():\n",
    "    temp = np.array(list(dict.values())).swapaxes(0, 1)\n",
    "    x_data = temp[:, :-1]\n",
    "    y_data = temp[:, [-1]]\n",
    "    X.assign(x_data)\n",
    "    Y.assign(y_data)\n",
    "    for step in range(2001):\n",
    "        train()\n",
    "        if step % 200 == 0:\n",
    "            print(i, step, \"Cost: \", cost().numpy())\n",
    "    i += 1\n",
    "\n",
    "h, c, a = hypothesis(), cost(), accuracy()\n",
    "print(\"Hypothesis: \", h, \"\\nCorrect (Y): \", c, \"\\nAccuracy: \", a)\n",
    "\n",
    "y_predict = tf.model.predict([[0.176471, 0.155779, 0, 0, 0, 0.052161, -0.952178, -0.733333]])\n",
    "print(\"Predict: {0}\".format(y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0c1fd8c-321a-4765-a23c-f4ea9b954c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(759, 8) (759, 1)\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9 (36.00 Byte)\n",
      "Trainable params: 9 (36.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 0s 674us/step - loss: 0.6342 - accuracy: 0.6433\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 0s 637us/step - loss: 0.5962 - accuracy: 0.6909\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 0s 635us/step - loss: 0.5709 - accuracy: 0.7009\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 0s 613us/step - loss: 0.5772 - accuracy: 0.7046\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 0s 627us/step - loss: 0.5688 - accuracy: 0.6971\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 0s 630us/step - loss: 0.5469 - accuracy: 0.7272\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 0s 653us/step - loss: 0.5459 - accuracy: 0.7196\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 0s 661us/step - loss: 0.5481 - accuracy: 0.7309\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 0s 623us/step - loss: 0.5385 - accuracy: 0.7309\n",
      "Epoch 10/10\n",
      " 85/200 [===========>..................] - ETA: 0s - loss: 0.5453 - accuracy: 0.7000WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2000 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2000 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 350us/step - loss: 0.5468 - accuracy: 0.7018\n",
      "Accuracy: 0.7017543911933899\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Predict: [[0.6079865]]\n",
      "24/24 [==============================] - 0s 700us/step - loss: 0.5354 - accuracy: 0.7339\n",
      "loss: 0.5353662371635437, accuracy: 0.7338603138923645\n"
     ]
    }
   ],
   "source": [
    "# Lab 5 Logistic Regression Classifier\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "xy = np.loadtxt('resource/data-03-diabetes.csv', delimiter=',', dtype=np.float32)\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "print(x_data.shape, y_data.shape)\n",
    "\n",
    "tf.model = tf.keras.Sequential()\n",
    "# multi-variable, x_data.shape[1] == feature counts == 8 in this case\n",
    "tf.model.add(tf.keras.layers.Dense(units=1, input_dim=x_data.shape[1], activation='sigmoid'))\n",
    "tf.model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.SGD(lr=0.01),  metrics=['accuracy'])\n",
    "tf.model.summary()\n",
    "\n",
    "history = tf.model.fit(x_data, y_data, epochs=10, steps_per_epoch=200)\n",
    "\n",
    "# accuracy!\n",
    "print(\"Accuracy: {0}\".format(history.history['accuracy'][-1]))\n",
    "\n",
    "# predict a single data point\n",
    "y_predict = tf.model.predict([[0.176471, 0.155779, 0, 0, 0, 0.052161, -0.952178, -0.733333]])\n",
    "print(\"Predict: {0}\".format(y_predict))\n",
    "\n",
    "# evaluating model\n",
    "evaluate = tf.model.evaluate(x_data, y_data)\n",
    "print(\"loss: {0}, accuracy: {1}\".format(evaluate[0], evaluate[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
