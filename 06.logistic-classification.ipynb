{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3dea1790-0bbd-4043-8fd0-ae9e1b3f966d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tf.Tensor(2.2992413, shape=(), dtype=float32)\n",
      "200 tf.Tensor(0.8299361, shape=(), dtype=float32)\n",
      "400 tf.Tensor(0.5783337, shape=(), dtype=float32)\n",
      "600 tf.Tensor(0.4779246, shape=(), dtype=float32)\n",
      "800 tf.Tensor(0.43126366, shape=(), dtype=float32)\n",
      "1000 tf.Tensor(0.4041064, shape=(), dtype=float32)\n",
      "1200 tf.Tensor(0.385075, shape=(), dtype=float32)\n",
      "1400 tf.Tensor(0.3699371, shape=(), dtype=float32)\n",
      "1600 tf.Tensor(0.35692653, shape=(), dtype=float32)\n",
      "1800 tf.Tensor(0.34523383, shape=(), dtype=float32)\n",
      "2000 tf.Tensor(0.3344582, shape=(), dtype=float32)\n",
      "2200 tf.Tensor(0.3243862, shape=(), dtype=float32)\n",
      "2400 tf.Tensor(0.31489566, shape=(), dtype=float32)\n",
      "2600 tf.Tensor(0.30591077, shape=(), dtype=float32)\n",
      "2800 tf.Tensor(0.2973801, shape=(), dtype=float32)\n",
      "3000 tf.Tensor(0.28926587, shape=(), dtype=float32)\n",
      "3200 tf.Tensor(0.28153783, shape=(), dtype=float32)\n",
      "3400 tf.Tensor(0.27417067, shape=(), dtype=float32)\n",
      "3600 tf.Tensor(0.2671421, shape=(), dtype=float32)\n",
      "3800 tf.Tensor(0.26043174, shape=(), dtype=float32)\n",
      "4000 tf.Tensor(0.2540213, shape=(), dtype=float32)\n",
      "4200 tf.Tensor(0.24789329, shape=(), dtype=float32)\n",
      "4400 tf.Tensor(0.24203192, shape=(), dtype=float32)\n",
      "4600 tf.Tensor(0.23642212, shape=(), dtype=float32)\n",
      "4800 tf.Tensor(0.23104972, shape=(), dtype=float32)\n",
      "5000 tf.Tensor(0.22590165, shape=(), dtype=float32)\n",
      "5200 tf.Tensor(0.2209655, shape=(), dtype=float32)\n",
      "5400 tf.Tensor(0.21622974, shape=(), dtype=float32)\n",
      "5600 tf.Tensor(0.2116834, shape=(), dtype=float32)\n",
      "5800 tf.Tensor(0.20731638, shape=(), dtype=float32)\n",
      "6000 tf.Tensor(0.203119, shape=(), dtype=float32)\n",
      "6200 tf.Tensor(0.19908239, shape=(), dtype=float32)\n",
      "6400 tf.Tensor(0.1951981, shape=(), dtype=float32)\n",
      "6600 tf.Tensor(0.19145824, shape=(), dtype=float32)\n",
      "6800 tf.Tensor(0.18785548, shape=(), dtype=float32)\n",
      "7000 tf.Tensor(0.18438278, shape=(), dtype=float32)\n",
      "7200 tf.Tensor(0.18103373, shape=(), dtype=float32)\n",
      "7400 tf.Tensor(0.17780204, shape=(), dtype=float32)\n",
      "7600 tf.Tensor(0.17468204, shape=(), dtype=float32)\n",
      "7800 tf.Tensor(0.1716683, shape=(), dtype=float32)\n",
      "8000 tf.Tensor(0.16875575, shape=(), dtype=float32)\n",
      "8200 tf.Tensor(0.16593957, shape=(), dtype=float32)\n",
      "8400 tf.Tensor(0.16321526, shape=(), dtype=float32)\n",
      "8600 tf.Tensor(0.16057858, shape=(), dtype=float32)\n",
      "8800 tf.Tensor(0.15802549, shape=(), dtype=float32)\n",
      "9000 tf.Tensor(0.15555224, shape=(), dtype=float32)\n",
      "9200 tf.Tensor(0.1531552, shape=(), dtype=float32)\n",
      "9400 tf.Tensor(0.15083112, shape=(), dtype=float32)\n",
      "9600 tf.Tensor(0.14857672, shape=(), dtype=float32)\n",
      "9800 tf.Tensor(0.14638904, shape=(), dtype=float32)\n",
      "10000 tf.Tensor(0.14426526, shape=(), dtype=float32)\n",
      "Hypothesis:  tf.Tensor(\n",
      "[[0.02857568]\n",
      " [0.15580688]\n",
      " [0.2943336 ]\n",
      " [0.7862358 ]\n",
      " [0.9425924 ]\n",
      " [0.98118603]], shape=(6, 1), dtype=float32) \n",
      "Correct (Y):  tf.Tensor(0.14426526, shape=(), dtype=float32) \n",
      "Accuracy:  tf.Tensor(1.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x_data = tf.constant([[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]], dtype=tf.float32)\n",
    "y_data = tf.constant([[0], [0], [0], [1], [1], [1]], dtype=tf.float32)\n",
    "\n",
    "X = tf.Variable(0., shape=tf.TensorShape(None), dtype = tf.float32)\n",
    "Y = tf.Variable(0., shape=tf.TensorShape(None), dtype = tf.float32)\n",
    "W = tf.Variable(tf.random.normal([2, 1]), name='weight')\n",
    "b = tf.Variable(tf.random.normal([1]), name='bias')\n",
    "\n",
    "# sigmoid function == tf.math.div(1. 1. + tf.math.exp(tf.linalg.matmul(X, W) + b))\n",
    "def hypothesis():\n",
    "    return tf.sigmoid(tf.linalg.matmul(X, W) + b)\n",
    "\n",
    "# 밥그릇 형태를 위한 2가지 로그함수 짬뽕 (Y값이 1과 0을 표현해야하므로)\n",
    "def cost(): \n",
    "    return -tf.reduce_mean(Y * tf.math.log(hypothesis()) + (1 - Y) * tf.math.log(1 - hypothesis()))\n",
    "\n",
    "# 경사하강법\n",
    "def train():\n",
    "    return tf.keras.optimizers.SGD(learning_rate = 0.01).minimize(cost, var_list=[W, b])\n",
    "\n",
    "# Hypothesis가 0.5 보다 크면 true, 외 false 처리하기 위해 float32로 캐스팅\n",
    "def predicted():\n",
    "    return tf.cast(hypothesis() > 0.5, dtype=tf.float32)\n",
    "\n",
    "# 정확도 계산, 예측값과 실 Y값이 얼마나 같은지를 평균\n",
    "def accuracy():\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(predicted(), Y), dtype=tf.float32))\n",
    "\n",
    "X.assign(x_data)\n",
    "Y.assign(y_data)\n",
    "for step in range(10001):\n",
    "    train()\n",
    "    if step % 200 == 0:\n",
    "        print(step, cost())\n",
    "\n",
    "h, c, a = hypothesis(), cost(), accuracy()\n",
    "print(\"Hypothesis: \", h, \"\\nCorrect (Y): \", c, \"\\nAccuracy: \", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a0afa900-f796-4c81-bf77-d50105703a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 Cost:  0.7289745\n",
      "0 200 Cost:  0.65987563\n",
      "0 400 Cost:  0.6390698\n",
      "0 600 Cost:  0.6274616\n",
      "0 800 Cost:  0.61828256\n",
      "0 1000 Cost:  0.61016774\n",
      "0 1200 Cost:  0.60278314\n",
      "0 1400 Cost:  0.5960096\n",
      "0 1600 Cost:  0.58977807\n",
      "0 1800 Cost:  0.58403444\n",
      "0 2000 Cost:  0.57873195\n",
      "1 0 Cost:  0.60603994\n",
      "1 200 Cost:  0.58460176\n",
      "1 400 Cost:  0.5697762\n",
      "1 600 Cost:  0.5572951\n",
      "1 800 Cost:  0.5461699\n",
      "1 1000 Cost:  0.53611016\n",
      "1 1200 Cost:  0.5269719\n",
      "1 1400 Cost:  0.5186485\n",
      "1 1600 Cost:  0.51105005\n",
      "1 1800 Cost:  0.504098\n",
      "1 2000 Cost:  0.49772298\n",
      "2 0 Cost:  0.6250257\n",
      "2 200 Cost:  0.62011474\n",
      "2 400 Cost:  0.6160234\n",
      "2 600 Cost:  0.61234707\n",
      "2 800 Cost:  0.6089851\n",
      "2 1000 Cost:  0.6058973\n",
      "2 1200 Cost:  0.6030566\n",
      "2 1400 Cost:  0.60044026\n",
      "2 1600 Cost:  0.5980279\n",
      "2 1800 Cost:  0.5958009\n",
      "2 2000 Cost:  0.59374243\n",
      "3 0 Cost:  0.5369883\n",
      "3 200 Cost:  0.5277223\n",
      "3 400 Cost:  0.5208709\n",
      "3 600 Cost:  0.51500887\n",
      "3 800 Cost:  0.5098064\n",
      "3 1000 Cost:  0.50513995\n",
      "3 1200 Cost:  0.50093234\n",
      "3 1400 Cost:  0.4971228\n",
      "3 1600 Cost:  0.49366063\n",
      "3 1800 Cost:  0.49050274\n",
      "3 2000 Cost:  0.48761237\n",
      "4 0 Cost:  0.52056676\n",
      "4 200 Cost:  0.49441573\n",
      "4 400 Cost:  0.4867378\n",
      "4 600 Cost:  0.4831855\n",
      "4 800 Cost:  0.4806967\n",
      "4 1000 Cost:  0.4785535\n",
      "4 1200 Cost:  0.47657531\n",
      "4 1400 Cost:  0.47471187\n",
      "4 1600 Cost:  0.47294512\n",
      "4 1800 Cost:  0.4712662\n",
      "4 2000 Cost:  0.46966785\n",
      "5 0 Cost:  0.39298847\n",
      "5 200 Cost:  0.38807833\n",
      "5 400 Cost:  0.38358557\n",
      "5 600 Cost:  0.37945998\n",
      "5 800 Cost:  0.3756612\n",
      "5 1000 Cost:  0.37215465\n",
      "5 1200 Cost:  0.36891028\n",
      "5 1400 Cost:  0.36590153\n",
      "5 1600 Cost:  0.36310506\n",
      "5 1800 Cost:  0.3605002\n",
      "5 2000 Cost:  0.35806885\n",
      "6 0 Cost:  0.48606202\n",
      "6 200 Cost:  0.4803667\n",
      "6 400 Cost:  0.47766295\n",
      "6 600 Cost:  0.47579885\n",
      "6 800 Cost:  0.47422937\n",
      "6 1000 Cost:  0.47281426\n",
      "6 1200 Cost:  0.47151133\n",
      "6 1400 Cost:  0.47030288\n",
      "6 1600 Cost:  0.46917778\n",
      "6 1800 Cost:  0.4681274\n",
      "6 2000 Cost:  0.46714437\n",
      "7 0 Cost:  0.49311933\n",
      "7 200 Cost:  0.4829333\n",
      "7 400 Cost:  0.47788635\n",
      "7 600 Cost:  0.47425848\n",
      "7 800 Cost:  0.47112623\n",
      "7 1000 Cost:  0.4682601\n",
      "7 1200 Cost:  0.4655948\n",
      "7 1400 Cost:  0.46310347\n",
      "7 1600 Cost:  0.46076906\n",
      "7 1800 Cost:  0.45857823\n",
      "7 2000 Cost:  0.456519\n",
      "Hypothesis:  tf.Tensor(\n",
      "[[0.8623904 ]\n",
      " [0.54518414]\n",
      " [0.7523589 ]\n",
      " [0.35782078]\n",
      " [0.58652705]\n",
      " [0.8184817 ]\n",
      " [0.08554523]\n",
      " [0.19507541]\n",
      " [0.7957873 ]\n",
      " [0.8020445 ]\n",
      " [0.7851956 ]\n",
      " [0.92799616]\n",
      " [0.7538879 ]\n",
      " [0.62339276]\n",
      " [0.74908775]\n",
      " [0.73323214]\n",
      " [0.6775425 ]\n",
      " [0.80433154]\n",
      " [0.47509927]\n",
      " [0.31455556]\n",
      " [0.8746276 ]\n",
      " [0.79735357]\n",
      " [0.6245383 ]\n",
      " [0.23069261]\n",
      " [0.88477665]\n",
      " [0.7405628 ]\n",
      " [0.8403918 ]\n",
      " [0.64505553]\n",
      " [0.9057175 ]\n",
      " [0.8686203 ]\n",
      " [0.7364292 ]\n",
      " [0.39036685]\n",
      " [0.90176415]\n",
      " [0.92409354]\n",
      " [0.24402654]\n",
      " [0.12404776]\n",
      " [0.7488145 ]\n",
      " [0.36155602]\n",
      " [0.8173784 ]\n",
      " [0.23318839]\n",
      " [0.27946594]\n",
      " [0.3142133 ]\n",
      " [0.77953947]\n",
      " [0.8697808 ]\n",
      " [0.09822734]\n",
      " [0.28483292]\n",
      " [0.5512539 ]\n",
      " [0.43476346]\n",
      " [0.42616946]\n",
      " [0.77508014]\n",
      " [0.07428069]\n",
      " [0.9296392 ]\n",
      " [0.12811783]\n",
      " [0.8389382 ]\n",
      " [0.691068  ]\n",
      " [0.7151655 ]\n",
      " [0.84000844]\n",
      " [0.5932251 ]\n",
      " [0.9036824 ]], shape=(59, 1), dtype=float32) \n",
      "Correct (Y):  tf.Tensor(0.456519, shape=(), dtype=float32) \n",
      "Accuracy:  tf.Tensor(0.7966102, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 당뇨병 예측 데이터 1~8->팩터, 9->당뇨X: 0 당뇨Y: 1\n",
    "dataset = tf.data.experimental.make_csv_dataset('resource/data-03-diabetes.csv', batch_size=100, num_epochs=1, shuffle=False, header=False, column_names=[1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "X = tf.Variable(1., dtype=tf.float32, shape=tf.TensorShape(None))\n",
    "Y = tf.Variable(1., dtype=tf.float32, shape=tf.TensorShape(None))\n",
    "\n",
    "W = tf.Variable(tf.random.normal([8, 1]), name='weight')\n",
    "b = tf.Variable(tf.random.normal([1]), name='bias')\n",
    "\n",
    "# sigmoid function == tf.math.div(1. 1. + tf.math.exp(tf.linalg.matmul(X, W) + b))\n",
    "def hypothesis():\n",
    "    return tf.sigmoid(tf.linalg.matmul(X, W) + b)\n",
    "\n",
    "# 밥그릇 형태를 위한 2가지 로그함수 짬뽕 (Y값이 1과 0을 표현해야하므로)\n",
    "def cost(): \n",
    "    return -tf.reduce_mean(Y * tf.math.log(hypothesis()) + (1 - Y) * tf.math.log(1 - hypothesis()))\n",
    "\n",
    "# 경사하강법\n",
    "def train():\n",
    "    return tf.keras.optimizers.SGD(learning_rate = 0.01).minimize(cost, var_list=[W, b])\n",
    "\n",
    "# Hypothesis가 0.5 보다 크면 true, 외 false 처리하기 위해 float32로 캐스팅\n",
    "def predicted():\n",
    "    return tf.cast(hypothesis() > 0.5, dtype=tf.float32)\n",
    "\n",
    "# 정확도 계산, 예측값과 실 Y값이 얼마나 같은지를 평균\n",
    "def accuracy():\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(predicted(), Y), dtype=tf.float32))\n",
    "\n",
    "i = 0\n",
    "for dict in dataset.as_numpy_iterator():\n",
    "    temp = np.array(list(dict.values())).swapaxes(0, 1)\n",
    "    x_data = temp[:, :-1]\n",
    "    y_data = temp[:, [-1]]\n",
    "    X.assign(x_data)\n",
    "    Y.assign(y_data)\n",
    "    for step in range(2001):\n",
    "        train()\n",
    "        if step % 200 == 0:\n",
    "            print(i, step, \"Cost: \", cost().numpy())\n",
    "    i += 1\n",
    "\n",
    "h, c, a = hypothesis(), cost(), accuracy()\n",
    "print(\"Hypothesis: \", h, \"\\nCorrect (Y): \", c, \"\\nAccuracy: \", a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
