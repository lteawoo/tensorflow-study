{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7fae9f5-bbad-467b-b787-6467b8af8a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 02:16:29.959003: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "693768df-cb57-411e-b55a-9332217c8cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩:  [1, 2, 3, 4, 6, 7]\n",
      "단어 집합:  {'the': 1, 'earth': 2, 'is': 3, 'an': 4, 'awesome': 5, 'place': 6, 'live': 7}\n"
     ]
    }
   ],
   "source": [
    "# 토큰화 훈련데이터로부터 단어 집합을 생성하고, 문장을 정수인코딩\n",
    "tokenizer = Tokenizer()\n",
    "train_text = \"The earth is an awesome place live\"\n",
    "\n",
    "# 단어 집합 생성\n",
    "tokenizer.fit_on_texts([train_text])\n",
    "\n",
    "# 정수 인코딩\n",
    "sub_text = \"The earth is an great place live\"\n",
    "sequences = tokenizer.texts_to_sequences([sub_text])[0]\n",
    "\n",
    "print(\"정수 인코딩: \", sequences)\n",
    "print(\"단어 집합: \", tokenizer.word_index) # great는 사전에 없어서 출력되지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41ca0530-904e-445c-a261-365a7b486f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6],\n",
       "       [0, 7, 8]], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 샘플의 길이를 동일하게 맞춰야할때 padding 과정을 거침\n",
    "pad_sequences([[1, 2, 3], [3, 4, 5, 6], [7, 8]], maxlen=3, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5362e321-75b5-4a94-95ea-37baf7043150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling\n",
    "# NN에서 입력층, 은닉층, 출력층 구조가 있음\n",
    "# 케라스에서는 이러한 층을 구성하기위해 Sequential을 사용\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# 예제\n",
    "#model = Sequential()\n",
    "#model.add(...) # 층 추가\n",
    "#model.add(...) # 층 추가\n",
    "#model.add(...) # 층 추가\n",
    "\n",
    "# 임베딩 층 추가 예제\n",
    "#model.add(Embedding(vocab_size, output_dim, input_length))\n",
    " \n",
    "# 전결합층(fully-connected layer)을 추가하는 예시\n",
    "#model.add(Dense(1, input_dim=3, activation='relu'))\n",
    "\n",
    "#- linear : 디폴트 값으로 별도 활성화 함수 없이 입력 뉴런과 가중치의 계산 결과 그대로 출력.\n",
    "#- sigmoid : 이진 분류 문제에서 출력층에 주로 사용되는 활성화 함수.\n",
    "#- softmax : 셋 이상의 선택지 중 하나를 택하는 다중 클래스 분류 문제에서 출력층에 주로 사용되는 활성화 함수.\n",
    "#- relu : 은닉층에 주로 사용되는 활성화 함수.\n",
    "\n",
    "# 모델의 정보를 요약해서 보여줌\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5be83f03-3228-4122-94c1-f27a234d2250",
   "metadata": {},
   "outputs": [],
   "source": [
    "#컴파일\n",
    "from tensorflow.keras.layers import SimpleRNN, Embedding, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "vocab_size = 10000\n",
    "embedding_dim = 32\n",
    "hidden_units = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim))\n",
    "model.add(SimpleRNN(hidden_units))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc']) # 모델을 기계가 이해할 수 있도록 컴파일\n",
    "\n",
    "# 문제 유형\t손실 함수명\t출력층의 활성화 함수명\t참고 실습\n",
    "# 회귀 문제\tmean_squared_error\t-\t선형 회귀 실습\n",
    "# 다중 클래스 분류\tcategorical_crossentropy\t소프트맥스\t로이터 뉴스 분류하기\n",
    "# 다중 클래스 분류\tsparse_categorical_crossentropy\t소프트맥스\t양방향 LSTM를 이용한 품사 태깅\n",
    "# 이진 분류\tbinary_crossentropy\t시그모이드\tIMDB 리뷰 감성 분류하기\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8761cb17-dbaf-48ce-96f3-61f00fdaa9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit 모델 학습을 시작, 오차로부터 매개 변수를 업데이트 시키는 과정을 학습, 훈련, 적합(fitting)이라고 하는데, 모델이 데이터에 적합해가는 과정이기 때문\n",
    "#model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "# X_train : 훈련 인자\n",
    "# y_train : 지도 학습에서 레이블 데이터에 해당함ㄷㄷㄷ\n",
    "# epochs =  에포크 1은 전체 데이터를 한번 훑고 지나간 것(총 훈련 횟수)\n",
    "# batch_size = 배치 크기, 기본값은 32, 미니 배치 경사 하강법을 사용하고 싶지 않을 때는 batch_size=None을 기재\n",
    "\n",
    "#model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0, validation_data(X_val, y_val))\n",
    "# validation_data = 검증데이터, 각 에포크 마다 검증 데이터의 정확도, 오차를 함께 출력, 훈련이 잘되고 있는지를 검증할때만 사용하고 훈련데이터로를 사용하지 않음\n",
    "# 검증 데이터의 오차(loss)가 낮아지다가 높아진다 -> 과적함(overfitting)의 신호\n",
    "\n",
    "#model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0, validation_split(=0.2))\n",
    "# validation split = validation_data와 동일하게 검증 데이터를 사용하기위한 용도, X_train과 y_train에서 일정 비율 분리하여 사용\n",
    "\n",
    "# verbose = 학습 중 출력되는 문구 설정\n",
    "# 0 : 아무것도 출력하지 안흠\n",
    "# 1 : 훈련의 진행도를 보여주는 진행 막대\n",
    "# 2 : 미니 배치마다 손실 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563ec127-b62d-40ef-a807-76db12cb3398",
   "metadata": {},
   "outputs": [],
   "source": [
    "#평가와 예측\n",
    "# evaluate: 테스트 데이터를 통해 학습한 모델에 대한 정확도를 평가\n",
    "# model.evaluate(X_test, y_test, batch_size=32)\n",
    "# X_test 테스트데이터\n",
    "# y_test 테스트데이터에 대한 레이블\n",
    "# batch_size 배치크기\n",
    "\n",
    "# predict: 임의의 입력에 대한 모델의 출력값을 확인합니다.\n",
    "# X_input 예측하고자하는 데이터\n",
    "# batch_size = 배치크기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002c76b1-f6f5-41ae-8595-359b01833cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델의 저장과 로드\n",
    "# 학습이 끝난 신경망의 구조를 보존하고 계속하여 사용하기 위함\n",
    "\n",
    "#model.save(\"model_name.h5\") hdf5 파일에 인공 신경망 모델을 저장\n",
    "\n",
    "#model = tensorflow.keras.models.load_model(\"model_name.h5\") 저장해둔 모델을 불러옴"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
