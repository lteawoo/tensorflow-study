{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f042944f-bed1-4072-9072-d254b4c46127",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-02 08:18:49.446461: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d3d4c92-02c7-4e38-85b9-1218f17937d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5)\n"
     ]
    }
   ],
   "source": [
    "train_X =  [[0.1, 4.2, 1.5, 1.1, 2.8], [1.0, 3.1, 2.5, 0.7, 1.1], [0.3, 2.1, 1.5, 2.1, 0.1], [2.2, 1.4, 0.5, 0.9, 1.1]]\n",
    "print(np.shape(train_X)) # 단어 벡터의 차원 5, 문장의 길이 4\n",
    "# 4번의 시점(timesteps)가 존재하고, 각 시점마다 5개의 단어 벡터가 입력으로 사용됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a313d17-50fe-4dc8-b22c-7636a87d3d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4, 5)\n"
     ]
    }
   ],
   "source": [
    "# 단 RNN은 2D텐서가 아니고 3D 텐서를 입력으로 받으므로 배치 크기 1을 추가\n",
    "train_X = [[[0.1, 4.2, 1.5, 1.1, 2.8], [1.0, 3.1, 2.5, 0.7, 1.1], [0.3, 2.1, 1.5, 2.1, 0.1], [2.2, 1.4, 0.5, 0.9, 1.1]]]\n",
    "train_X = np.array(train_X, dtype=np.float32)\n",
    "print(train_X.shape) # batch_size는 1이고 RNN이 학번에 학습하는 양"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ac7f46a-0d31-4631-9b83-d7cc3f3cc74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden states = [[-0.57475626  0.25164804 -0.04415815]], shape: (1, 3)\n",
      "last hidden state = [[-0.57475626  0.25164804 -0.04415815]], shape: (1, 3)\n",
      "last_cell_state = [[-1.4341611   0.5343475  -0.26574236]], shape: (1, 3)\n"
     ]
    }
   ],
   "source": [
    "lstm = LSTM(3, return_sequences=False, return_state=True)\n",
    "hidden_states, last_state, last_cell_state = lstm(train_X)\n",
    "\n",
    "print('hidden states = {}, shape: {}'.format(hidden_states, hidden_states.shape))\n",
    "print('last hidden state = {}, shape: {}'.format(last_state, last_state.shape))\n",
    "print('last_cell_state = {}, shape: {}'.format(last_cell_state, last_cell_state.shape))\n",
    "\n",
    "# simpleRNN과 다르게 3개의 출력을 반환, return_sequences가 False이므로 첫번째는 마지막 시점의 은닉상태\n",
    "# return_state가 True인경우 마지막 셀의 상태까지 반환한다는점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e960a81-ca27-4d80-9f8d-644f3997bded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden states = [[[-0.5541065   0.18113732 -0.48967132]\n",
      "  [-0.4707675  -0.03360611 -0.75242496]\n",
      "  [-0.26216856 -0.03199646 -0.5714816 ]\n",
      "  [-0.35336885 -0.01527879 -0.7253603 ]]], shape: (1, 4, 3)\n",
      "last hidden state = [[-0.35336885 -0.01527879 -0.7253603 ]], shape: (1, 3)\n",
      "last_cell_state = [[-0.92141896 -0.04457372 -1.7044477 ]], shape: (1, 3)\n"
     ]
    }
   ],
   "source": [
    "#return sequences를 True로 바꿔보자\n",
    "lstm = LSTM(3, return_sequences=True, return_state=True)\n",
    "hidden_states, last_state, last_cell_state = lstm(train_X)\n",
    "\n",
    "print('hidden states = {}, shape: {}'.format(hidden_states, hidden_states.shape))\n",
    "print('last hidden state = {}, shape: {}'.format(last_state, last_state.shape))\n",
    "print('last_cell_state = {}, shape: {}'.format(last_cell_state, last_cell_state.shape))\n",
    "\n",
    "# 모든 시점의 은닉상태가 출력되는 거 외에는 동일하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcbf3f3f-6c8d-4477-b606-80f8b5f90990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden states : [[0.6303138 0.6303138 0.6303138 0.7038734 0.7038734 0.7038734]], shape: (1, 6)\n",
      "forward state : [[0.6303138 0.6303138 0.6303138]], shape: (1, 3)\n",
      "backward state : [[0.7038734 0.7038734 0.7038734]], shape: (1, 3)\n"
     ]
    }
   ],
   "source": [
    "# 양방향 LSTM의 출력값을 확인해보자.\n",
    "# return_sequences가 True인 경우와 False인 경우에 대해서 은닉 상태의 값이 어떻게 바뀌는지 직접 비교하기 위해서 출력되는 은닉 상태의 값을 고정\n",
    "\n",
    "k_init = tf.keras.initializers.Constant(value=0.1)\n",
    "b_init = tf.keras.initializers.Constant(value=0)\n",
    "r_init = tf.keras.initializers.Constant(value=0.1)\n",
    "\n",
    "# return_sequences가 False이고, return_state가 True인 경우\n",
    "bilstm = Bidirectional(LSTM(3, return_sequences=False, return_state=True, \\\n",
    "                       kernel_initializer=k_init, bias_initializer=b_init, recurrent_initializer=r_init))\n",
    "hidden_states, forward_h, forward_c, backward_h, backward_c = bilstm(train_X)\n",
    "\n",
    "print('hidden states : {}, shape: {}'.format(hidden_states, hidden_states.shape)) # 아래 두개를 연결 한 값이 이 값\n",
    "print('forward state : {}, shape: {}'.format(forward_h, forward_h.shape)) # 정방향 LSTM의 마지막 시점의 은닉 상태\n",
    "print('backward state : {}, shape: {}'.format(backward_h, backward_h.shape)) # 역방향 LSTM의 첫번째 시점의 은닉 상태\n",
    "\n",
    "# 5개의 출력값이 존재\n",
    "# return_state가 True인 경우에는 정방향 LSTM의 은닉 상태와 셀 상태, 역방향 LSTM의 은닉 상태와 셀 상태 4가지를 반환하기 때문\n",
    "# 첫번째 출력값이 (1, 6)인 이유는 return_sequences가 False인 경우 정방향 LSTM의 마지막시점의 은닉 상태와 역방향 LSTM의 첫번째 시점의 은닉상태가 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18a27cf3-e3eb-421d-a5cd-bd700be6674c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden states : [[[0.35906473 0.35906473 0.35906473 0.7038734  0.7038734  0.7038734 ]\n",
      "  [0.55111325 0.55111325 0.55111325 0.58863586 0.58863586 0.58863586]\n",
      "  [0.59115744 0.59115744 0.59115744 0.3951699  0.3951699  0.3951699 ]\n",
      "  [0.6303138  0.6303138  0.6303138  0.21942244 0.21942244 0.21942244]]], shape: (1, 4, 6)\n",
      "forward state : [[0.6303138 0.6303138 0.6303138]], shape: (1, 3)\n",
      "backward state : [[0.7038734 0.7038734 0.7038734]], shape: (1, 3)\n"
     ]
    }
   ],
   "source": [
    "# return_sequences=True인 경우\n",
    "bilstm = Bidirectional(LSTM(3, return_sequences=True, return_state=True, \\\n",
    "                       kernel_initializer=k_init, bias_initializer=b_init, recurrent_initializer=r_init))\n",
    "hidden_states, forward_h, forward_c, backward_h, backward_c = bilstm(train_X)\n",
    "\n",
    "print('hidden states : {}, shape: {}'.format(hidden_states, hidden_states.shape)) # 모든 시점의 은닉 상태\n",
    "print('forward state : {}, shape: {}'.format(forward_h, forward_h.shape)) # 정방향 LSTM의 마지막 시점의 은닉 상태\n",
    "print('backward state : {}, shape: {}'.format(backward_h, backward_h.shape)) # 역방향 LSTM의 첫번째 시점의 은닉 상태\n",
    "# hidden states를 보면 역방향 첫번째 시점의 은닉 상태는 더이상 정방향 마지막 시점의 은닉 상태와 연결되지 않은 것을 볼 수있다\n",
    "# 정방향 첫번째 시점과 연결되어 있다. (모든 시점의 은닉 상태를 출력하므로)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
